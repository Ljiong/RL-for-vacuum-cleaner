{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.environment import UnityEnvironment as UE\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from collections import deque\n",
    "from dqn_agent_Original import Agent\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_PATH = \"../environment-MAC/en.app\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialise customised Banana Collecter environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_env(ENV_PATH):\n",
    "    # env = UnityEnvironment(file_name=ENV_PATH)\n",
    "    env = UE(base_port=5004,file_name=ENV_PATH, seed=1, side_channels=[])\n",
    "    env.step()\n",
    "    # in this project, we are only using one agent, so we will only work on the first `brain` in the environmet\n",
    "    # get the default brain\n",
    "    # brain_name = env.brain_names[0]\n",
    "    brain_name = list(env.behavior_specs.keys())[0]\n",
    "    # brain = env.brains[brain_name]\n",
    "    brain = env.behavior_specs[brain_name]\n",
    "    return env, brain, brain_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0621 11:12:35.206811000 8602516992 fork_posix.cc:76]                  Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n"
     ]
    }
   ],
   "source": [
    "env, brain, brain_name = initialise_env(ENV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialise the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = env.behavior_specs['My Behavior?team=0']\n",
    "# print(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = list(brain.action_spec)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = len(brain.observation_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ObservationSpec(shape=(265,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='RayPerceptionSensor'),\n",
       " ObservationSpec(shape=(245,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='RayPerceptionSensor-3'),\n",
       " ObservationSpec(shape=(0,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor'),\n",
       " ObservationSpec(shape=(4,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor_size4')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain.observation_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "for act in range(5):\n",
    "    actions.append(spec.action_spec.empty_action(1))\n",
    "    actions[act].add_discrete(np.int32([[act]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(agent, n_episodes=2, max_t=500, eps_start=1.0, eps_end=0.1, eps_decay=0.98):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    average_scores = []\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "#     rewards =0\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        # every episode we reset the environment to start state\n",
    "        env.reset()\n",
    "#         print(\"~~~~~~~~~~~~~~~~~~~~\")\n",
    "        decision_steps, terminal_steps = env.get_steps(brain_name)\n",
    "        ray_sensor_1 = decision_steps.obs[0]\n",
    "        ray_sensor_2 = decision_steps.obs[1]\n",
    "        state = np.concatenate((ray_sensor_1, ray_sensor_2), axis=1)\n",
    "        \n",
    "        tracked_agent = -1\n",
    "        done = False\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            reward = 0\n",
    "            if tracked_agent == -1 and len(decision_steps) >= 1:\n",
    "                tracked_agent = decision_steps.agent_id[0]\n",
    "            action = agent.act(state, eps)\n",
    "            env.set_actions(brain_name, actions[action])\n",
    "            env.step()\n",
    "            \n",
    "            decision_steps, terminal_steps = env.get_steps(brain_name)\n",
    "            if len(decision_steps.obs[0]) != 1:\n",
    "                env.reset()\n",
    "            else: \n",
    "                ray_sensor_1 = decision_steps.obs[0]\n",
    "                \n",
    "            if len(decision_steps.obs[1]) != 1:\n",
    "                env.reset()\n",
    "            else: \n",
    "                ray_sensor_2 = decision_steps.obs[1]\n",
    "                \n",
    "            if len(decision_steps.obs[3]) == 0:\n",
    "                env.reset()\n",
    "            else: \n",
    "                battery = decision_steps.obs[3][0][0]\n",
    "\n",
    "            next_state = np.concatenate((ray_sensor_1, ray_sensor_2), axis=1)\n",
    "            \n",
    "            if battery == 0: # if the battery use up, give a penalty\n",
    "                reward = -2\n",
    "            else:\n",
    "                reward = 0\n",
    "\n",
    "            if tracked_agent in decision_steps:# The agent requested a decision\n",
    "                reward += decision_steps[tracked_agent].reward  # get the reward\n",
    "                agent.step(state, action, reward, next_state, False)\n",
    "            if tracked_agent in terminal_steps: # The agent terminated its episode\n",
    "                reward += terminal_steps[tracked_agent].reward# get the reward\n",
    "                agent.step(state, action, reward, next_state, True)\n",
    "                break\n",
    "                \n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "        \n",
    "        scores_window.append(score)       # save most recent score\n",
    "#         print(scores_window)\n",
    "        scores.append(score)              # save most recent score\n",
    "        average_scores.append(np.mean(scores))\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores)))\n",
    "        print('\\rEpisode {}\\tScore: {:.2f}'.format(i_episode, score))\n",
    "        if i_episode % 50 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            print('saved temporary learned weight')\n",
    "#         if np.mean(scores_window)>=500.0:\n",
    "#             print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "#             torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "#             print('agent done training')\n",
    "#             break\n",
    "    return scores, average_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: 4.00\n",
      "Episode 1\tScore: 4.00\n",
      "Episode 2\tAverage Score: -2.00\n",
      "Episode 2\tScore: -8.00\n",
      "Episode 3\tAverage Score: 0.00\n",
      "Episode 3\tScore: 4.00\n",
      "Episode 4\tAverage Score: 0.25\n",
      "Episode 4\tScore: 1.00\n",
      "Episode 5\tAverage Score: 0.60\n",
      "Episode 5\tScore: 2.00\n",
      "Episode 6\tAverage Score: 0.83\n",
      "Episode 6\tScore: 2.00\n",
      "Episode 7\tAverage Score: 1.29\n",
      "Episode 7\tScore: 4.00\n",
      "Episode 8\tAverage Score: 1.25\n",
      "Episode 8\tScore: 1.00\n",
      "Episode 9\tAverage Score: 1.78\n",
      "Episode 9\tScore: 6.00\n",
      "Episode 10\tAverage Score: 2.00\n",
      "Episode 10\tScore: 4.00\n",
      "Episode 11\tAverage Score: 1.82\n",
      "Episode 11\tScore: 0.00\n",
      "Episode 12\tAverage Score: 1.75\n",
      "Episode 12\tScore: 1.00\n",
      "Episode 13\tAverage Score: 1.85\n",
      "Episode 13\tScore: 3.00\n",
      "Episode 14\tAverage Score: 1.57\n",
      "Episode 14\tScore: -2.00\n",
      "Episode 15\tAverage Score: 0.60\n",
      "Episode 15\tScore: -13.00\n",
      "Episode 16\tAverage Score: 0.12\n",
      "Episode 16\tScore: -7.00\n",
      "Episode 17\tAverage Score: 0.12\n",
      "Episode 17\tScore: 0.00\n",
      "Episode 18\tAverage Score: -0.06\n",
      "Episode 18\tScore: -3.00\n",
      "Episode 19\tAverage Score: -0.63\n",
      "Episode 19\tScore: -11.00\n",
      "Episode 20\tAverage Score: -0.30\n",
      "Episode 20\tScore: 6.00\n",
      "Episode 21\tAverage Score: -0.14\n",
      "Episode 21\tScore: 3.00\n",
      "Episode 22\tAverage Score: -0.41\n",
      "Episode 22\tScore: -6.00\n",
      "Episode 23\tAverage Score: -0.52\n",
      "Episode 23\tScore: -3.00\n",
      "Episode 24\tAverage Score: -0.38\n",
      "Episode 24\tScore: 3.00\n",
      "Episode 25\tAverage Score: -0.32\n",
      "Episode 25\tScore: 1.00\n",
      "Episode 26\tAverage Score: -0.81\n",
      "Episode 26\tScore: -13.00\n",
      "Episode 27\tAverage Score: -1.00\n",
      "Episode 27\tScore: -6.00\n",
      "Episode 28\tAverage Score: -0.86\n",
      "Episode 28\tScore: 3.00\n",
      "Episode 29\tAverage Score: -0.59\n",
      "Episode 29\tScore: 7.00\n",
      "Episode 30\tAverage Score: -0.47\n",
      "Episode 30\tScore: 3.00\n",
      "Episode 31\tAverage Score: -0.52\n",
      "Episode 31\tScore: -2.00\n",
      "Episode 32\tAverage Score: -0.53\n",
      "Episode 32\tScore: -1.00\n",
      "Episode 33\tAverage Score: -0.42\n",
      "Episode 33\tScore: 3.00\n",
      "Episode 34\tAverage Score: -0.44\n",
      "Episode 34\tScore: -1.00\n",
      "Episode 35\tAverage Score: -0.26\n",
      "Episode 35\tScore: 6.00\n",
      "Episode 36\tAverage Score: -0.14\n",
      "Episode 36\tScore: 4.00\n",
      "Episode 37\tAverage Score: -0.32\n",
      "Episode 37\tScore: -7.00\n",
      "Episode 38\tAverage Score: -0.32\n",
      "Episode 38\tScore: 0.00\n",
      "Episode 39\tAverage Score: -0.44\n",
      "Episode 39\tScore: -5.00\n",
      "Episode 40\tAverage Score: -0.40\n",
      "Episode 40\tScore: 1.00\n",
      "Episode 41\tAverage Score: -0.41\n",
      "Episode 41\tScore: -1.00\n",
      "Episode 42\tAverage Score: -0.52\n",
      "Episode 42\tScore: -5.00\n",
      "Episode 43\tAverage Score: -0.60\n",
      "Episode 43\tScore: -4.00\n",
      "Episode 44\tAverage Score: -0.66\n",
      "Episode 44\tScore: -3.00\n",
      "Episode 45\tAverage Score: -0.64\n",
      "Episode 45\tScore: 0.00\n",
      "Episode 46\tAverage Score: -0.57\n",
      "Episode 46\tScore: 3.00\n",
      "Episode 47\tAverage Score: -0.53\n",
      "Episode 47\tScore: 1.00\n",
      "Episode 48\tAverage Score: -0.50\n",
      "Episode 48\tScore: 1.00\n",
      "Episode 49\tAverage Score: -0.39\n",
      "Episode 49\tScore: 5.00\n",
      "Episode 50\tAverage Score: -0.32\n",
      "Episode 50\tScore: 3.00\n",
      "Episode 50\tAverage Score: -0.32\n",
      "saved temporary learned weight\n",
      "Episode 51\tAverage Score: -0.39\n",
      "Episode 51\tScore: -4.00\n",
      "Episode 52\tAverage Score: -0.33\n",
      "Episode 52\tScore: 3.00\n",
      "Episode 53\tAverage Score: -0.32\n",
      "Episode 53\tScore: 0.00\n",
      "Episode 54\tAverage Score: -0.37\n",
      "Episode 54\tScore: -3.00\n",
      "Episode 55\tAverage Score: -0.31\n",
      "Episode 55\tScore: 3.00\n",
      "Episode 56\tAverage Score: -0.27\n",
      "Episode 56\tScore: 2.00\n",
      "Episode 57\tAverage Score: -0.40\n",
      "Episode 57\tScore: -8.00\n",
      "Episode 58\tAverage Score: -0.34\n",
      "Episode 58\tScore: 3.00\n",
      "Episode 59\tAverage Score: -0.39\n",
      "Episode 59\tScore: -3.00\n",
      "Episode 60\tAverage Score: -0.43\n",
      "Episode 60\tScore: -3.00\n",
      "Episode 61\tAverage Score: -0.41\n",
      "Episode 61\tScore: 1.00\n",
      "Episode 62\tAverage Score: -0.50\n",
      "Episode 62\tScore: -6.00\n",
      "Episode 63\tAverage Score: -0.44\n",
      "Episode 63\tScore: 3.00\n",
      "Episode 64\tAverage Score: -0.33\n",
      "Episode 64\tScore: 7.00\n",
      "Episode 65\tAverage Score: -0.45\n",
      "Episode 65\tScore: -8.00\n",
      "Episode 66\tAverage Score: -0.48\n",
      "Episode 66\tScore: -3.00\n",
      "Episode 67\tAverage Score: -0.43\n",
      "Episode 67\tScore: 3.00\n",
      "Episode 68\tAverage Score: -0.49\n",
      "Episode 68\tScore: -4.00\n",
      "Episode 69\tAverage Score: -0.49\n",
      "Episode 69\tScore: -1.00\n",
      "Episode 70\tAverage Score: -0.46\n",
      "Episode 70\tScore: 2.00\n",
      "Episode 71\tAverage Score: -0.44\n",
      "Episode 71\tScore: 1.00\n",
      "Episode 72\tAverage Score: -0.53\n",
      "Episode 72\tScore: -7.00\n",
      "Episode 73\tAverage Score: -0.53\n",
      "Episode 73\tScore: -1.00\n",
      "Episode 74\tAverage Score: -0.58\n",
      "Episode 74\tScore: -4.00\n",
      "Episode 75\tAverage Score: -0.57\n",
      "Episode 75\tScore: 0.00\n",
      "Episode 76\tAverage Score: -0.53\n",
      "Episode 76\tScore: 3.00\n",
      "Episode 77\tAverage Score: -0.56\n",
      "Episode 77\tScore: -3.00\n",
      "Episode 78\tAverage Score: -0.59\n",
      "Episode 78\tScore: -3.00\n",
      "Episode 79\tAverage Score: -0.58\n",
      "Episode 79\tScore: 0.00\n",
      "Episode 80\tAverage Score: -0.53\n",
      "Episode 80\tScore: 4.00\n",
      "Episode 81\tAverage Score: -0.58\n",
      "Episode 81\tScore: -5.00\n",
      "Episode 82\tAverage Score: -0.54\n",
      "Episode 82\tScore: 3.00\n",
      "Episode 83\tAverage Score: -0.48\n",
      "Episode 83\tScore: 4.00\n",
      "Episode 84\tAverage Score: -0.49\n",
      "Episode 84\tScore: -1.00\n",
      "Episode 85\tAverage Score: -0.51\n",
      "Episode 85\tScore: -2.00\n",
      "Episode 86\tAverage Score: -0.52\n",
      "Episode 86\tScore: -2.00\n",
      "Episode 87\tAverage Score: -0.51\n",
      "Episode 87\tScore: 1.00\n",
      "Episode 88\tAverage Score: -0.59\n",
      "Episode 88\tScore: -8.00\n",
      "Episode 89\tAverage Score: -0.55\n",
      "Episode 89\tScore: 3.00\n",
      "Episode 90\tAverage Score: -0.52\n",
      "Episode 90\tScore: 2.00\n",
      "Episode 91\tAverage Score: -0.45\n",
      "Episode 91\tScore: 6.00\n",
      "Episode 92\tAverage Score: -0.42\n",
      "Episode 92\tScore: 2.00\n",
      "Episode 93\tAverage Score: -0.38\n",
      "Episode 93\tScore: 4.00\n",
      "Episode 94\tAverage Score: -0.41\n",
      "Episode 94\tScore: -4.00\n",
      "Episode 95\tAverage Score: -0.35\n",
      "Episode 95\tScore: 6.00\n",
      "Episode 96\tAverage Score: -0.31\n",
      "Episode 96\tScore: 3.00\n",
      "Episode 97\tAverage Score: -0.28\n",
      "Episode 97\tScore: 3.00\n",
      "Episode 98\tAverage Score: -0.24\n",
      "Episode 98\tScore: 3.00\n",
      "Episode 99\tAverage Score: -0.22\n",
      "Episode 99\tScore: 2.00\n",
      "Episode 100\tAverage Score: -0.25\n",
      "Episode 100\tScore: -3.00\n",
      "Episode 100\tAverage Score: -0.25\n",
      "saved temporary learned weight\n"
     ]
    }
   ],
   "source": [
    "# if os.path.isfile('./checkpoint.pth'):\n",
    "#     # load the weights from file\n",
    "#     agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "    \n",
    "scores, average_scores = train_dqn(agent, n_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0, -8.0, 4.0, 1.0, 2.0, 2.0, 4.0, 1.0, 6.0, 4.0, 0.0, 1.0, 3.0, -2.0, -13.0, -7.0, 0.0, -3.0, -11.0, 6.0, 3.0, -6.0, -3.0, 3.0, 1.0, -13.0, -6.0, 3.0, 7.0, 3.0, -2.0, -1.0, 3.0, -1.0, 6.0, 4.0, -7.0, 0.0, -5.0, 1.0, -1.0, -5.0, -4.0, -3.0, 0.0, 3.0, 1.0, 1.0, 5.0, 3.0, -4.0, 3.0, 0.0, -3.0, 3.0, 2.0, -8.0, 3.0, -3.0, -3.0, 1.0, -6.0, 3.0, 7.0, -8.0, -3.0, 3.0, -4.0, -1.0, 2.0, 1.0, -7.0, -1.0, -4.0, 0.0, 3.0, -3.0, -3.0, 0.0, 4.0, -5.0, 3.0, 4.0, -1.0, -2.0, -2.0, 1.0, -8.0, 3.0, 2.0, 6.0, 2.0, 4.0, -4.0, 6.0, 3.0, 3.0, 3.0, 2.0, -3.0]\n",
      "[4.0, -2.0, 0.0, 0.25, 0.6, 0.8333333333333334, 1.2857142857142858, 1.25, 1.7777777777777777, 2.0, 1.8181818181818181, 1.75, 1.8461538461538463, 1.5714285714285714, 0.6, 0.125, 0.11764705882352941, -0.05555555555555555, -0.631578947368421, -0.3, -0.14285714285714285, -0.4090909090909091, -0.5217391304347826, -0.375, -0.32, -0.8076923076923077, -1.0, -0.8571428571428571, -0.5862068965517241, -0.4666666666666667, -0.5161290322580645, -0.53125, -0.42424242424242425, -0.4411764705882353, -0.2571428571428571, -0.1388888888888889, -0.32432432432432434, -0.3157894736842105, -0.4358974358974359, -0.4, -0.4146341463414634, -0.5238095238095238, -0.6046511627906976, -0.6590909090909091, -0.6444444444444445, -0.5652173913043478, -0.5319148936170213, -0.5, -0.3877551020408163, -0.32, -0.39215686274509803, -0.3269230769230769, -0.32075471698113206, -0.37037037037037035, -0.3090909090909091, -0.26785714285714285, -0.40350877192982454, -0.3448275862068966, -0.3898305084745763, -0.43333333333333335, -0.4098360655737705, -0.5, -0.4444444444444444, -0.328125, -0.4461538461538462, -0.48484848484848486, -0.43283582089552236, -0.4852941176470588, -0.4927536231884058, -0.45714285714285713, -0.43661971830985913, -0.5277777777777778, -0.5342465753424658, -0.581081081081081, -0.5733333333333334, -0.5263157894736842, -0.5584415584415584, -0.5897435897435898, -0.5822784810126582, -0.525, -0.5802469135802469, -0.5365853658536586, -0.4819277108433735, -0.4880952380952381, -0.5058823529411764, -0.5232558139534884, -0.5057471264367817, -0.5909090909090909, -0.550561797752809, -0.5222222222222223, -0.45054945054945056, -0.42391304347826086, -0.3763440860215054, -0.4148936170212766, -0.3473684210526316, -0.3125, -0.27835051546391754, -0.24489795918367346, -0.2222222222222222, -0.25]\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(average_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwuElEQVR4nO3deXxV5bXw8d8652SeIJAAIUCYkVEwimOd6wBq6zy1tnqLrbbX1rZefa299r32tm+1tdapaqu11jrWWasIAopzQOYxjBIICQIZyXjW+8c+CQkZOCRnn0Oy1/fzyYdkn7Cf54Fkr7OeUVQVY4wx3uOLdQWMMcbEhgUAY4zxKAsAxhjjURYAjDHGoywAGGOMRwViXYFD0b9/f83Ly4t1NYwxpkdZtGjRLlXNOvB6jwoAeXl5FBQUxLoaxhjTo4jIlvauWxeQMcZ4lAUAY4zxKAsAxhjjURYAjDHGoywAGGOMR8U8AIiIX0S+EJE3Yl0XY4zxkpgHAOAmYHWsK2GMMV4T0wAgIrnADOAvbpYzZ9VOHppf6GYRxhjT48Q6A/gjcAsQ7OgbRGSWiBSISEFpaWmXClmwrpTH3t/YtRoaY0wvFbMAICIzgRJVXdTZ96nqo6qar6r5WVltVjKHxe8TGoJ28I0xxrQUywzgBOB8EdkMPAucJiL/cKOggE9otABgjDGtxCwAqOptqpqrqnnA5cB7qnq1G2X5/ZYBGGPMgWI9BhAVAZ8QtABgjDGtHBa7garqfGC+W/f3+3w0BBVVRUTcKsYYY3oUz2QAAJYEGGPMfp4IAP5QAGgIdjjb1BhjPMcTAaApA7CZQMYYs58nAsD+DMACgDHGNPFEAGjOABotABhjTBNPBAC/32mmZQDGGLOfJwKAjQEYY0xbnggANgvIGGPa8kQAsAzAGGPa8kQAsFlAxhjTlicCQMDnNNMyAGOM2c8TAaA5A7BpoMYY08wTAcDGAIwxpi1PBAC/32YBGWPMgTwRACwDMMaYtjwRAGwWkDHGtOWJAGCzgIwxpi1PBADLAIwxpi1PBID9YwA2CGyMMU08EQBsHYAxxrTliQAQ8NssIGOMOZA3AoCNARhjTBueCAB+mwVkjDFteCIAWAZgjDFtxSwAiEiiiHwmIktFZKWI/Mqtsvw2C8gYY9oIxLDsWuA0Va0UkThgoYj8W1U/iXRBlgEYY0xbMQsAqqpAZejLuNCHK09ov+0FZIwxbcR0DEBE/CKyBCgB3lXVT9v5nlkiUiAiBaWlpV0qp2krCFsHYIwx+8U0AKhqo6oeCeQCx4jIxHa+51FVzVfV/KysrC6V47d1AMYY08ZhMQtIVfcC84Gz3bi/jQEYY0xbsZwFlCUifUKfJwFnAGvcKMtmARljTFuxnAU0CHhSRPw4geh5VX3DjYL8YhmAMcYcKJazgJYBU6NRls8n+MTGAIwxpqXDYgwgGgI+n2UAxhjTgmcCgN8nlgEYY0wLngkAAZ/YOgBjjGnBMwHA7xebBWSMMS14JgAEfGJjAMYY04JnAoCNARhjTGueCQA2C8gYY1rzTACwDMAYY1rzTACwMQBjjGnNMwHAyQBsFpAxxjTxVACwdQDGGLOfZwJAwG9jAMYY05JnAoDfZgEZY0wr3gkAthuoMca04pkA4KwDsEFgY4xp4pkAYOsAjDGmNc8EgIDf1gEYY0xLngkAlgEYY0xrngkAdh6AMca05pkA4PcJQbUAYIwxTTwTAGw3UGOMac0zAcDGAIwxpjXPBABnN1BbB2CMMU0OGgBE5AQRSQl9frWI/EFEhrlftcjy+4RGGwQ2xphm4WQADwPVIjIFuAXYAvy9uwWLyBARmSciq0VkpYjc1N17dsbWARhjTGvhBIAGVVXgAuA+Vb0PSItA2Q3AT1X1COBY4EYRGR+B+7bLxgCMMaa1cAJAhYjcBnwLeFNE/EBcdwtW1R2qujj0eQWwGhjc3ft2JJqzgP7xyRYWbdkdlbKMMaarwgkAlwG1wLWqWozzkL47kpUQkTxgKvBpO6/NEpECESkoLS3tchnRygA276riF6+s4GcvLKOh0QadjTGHr4MGgNBD/19AQujSLuDlSFVARFJD9/+xqpa3U/6jqpqvqvlZWVldLidas4Ce+mQLAJt2VfHSF0Wul2eMMV0Vziyg7wEvAo+ELg0GXolE4SISh/Pwf1pVX4rEPTsSjQyguq6BFwq+ZMbkQUzOzeBPc9dT12BZgDHm8BROF9CNwAlAOYCqrgeyu1uwiAjwV2C1qv6hu/c7GCcDcDcAvLpkO+U1DVxzXB43nzmGbXv28XzBl66WaYwxXRVOAKhV1bqmL0QkAETiSXoCzsDyaSKyJPRxbgTu2y6/z4cqBF0KAqrK3z/ewriBaRyd15eTx2SRP6wvD7xXSE19Y5vv/2zTbj5Y3/UxDWOM6a5wAsACEfk/QJKInAm8ALze3YJVdaGqiqpOVtUjQx9vdfe+HQn4BcC1LKBgyx5W7yjn28flISKICDd/fQzF5TU8smAj2mIjujmrdnLlY59w49OLrYvIGBMz4QSA/wJKgeXA9cBbwC/crJQb/D4nALg1DvD3j7eQlhjgG1Nzmq8dP7I/Z08YyL1z1vHj55ZQUVPPgnWl3PD0YjJT4imvaWBhoWUBxpjYCHT2ooj4gGWqOhF4LDpVckfA15QBBAF/RO9d29DI2yt2cOUxQ0mOb/1P+uBV03hoXiH3zlnHoi17KK2oZVR2Kk9eewxn/GEBbyzdwWnjBkS0PsYYE45OMwBVDQJLRWRolOrjGjczgMKSSuoblfy8zHbL/dHpo3n++uNQhbx+KTx13TFkpSVw1oQBzF61s90xAmOMcVunGUDIIGCliHwGVDVdVNXzXauVC/ZnAJEPAGuLKwAYN7DjHTLy8zKZ//NTUIX4gBN3Z07O4fmCbSxYV8pZEwZGvF7GGNOZcALAr1yvRRT4fc5D140MYE1xBfF+H3n9Uzr9vjh/64Tr+JH9yEyJ541lOywAGGOiLpyVwAuANTgbwKXhzNtf4HbFIs3NDGBNcQWjslPbPOAPWie/j7MnDmTu6p3sq7NuIGNMdIWzEvhS4DPgEuBS4FMRudjtikVa8xiAC2cCrC0u77T7pzMzJw+iuq6R99aURLhWxhjTuXC6gG4HjlbVEgARyQLm4GwP0WPsXwcQ2Xn3e6vr2Fley9guBoDpw/vRPzWBN5dvZ8bkQRGtmzHGdCacPgtf08M/5Ksw/95hxa1ZQGuaBoAHpXfp7/t9wqljs/h0o20fbYyJrnAygLdF5B3gmdDXlwH/dq9K7nBrDGDNDmcD0652AQHk9Elid3Ud9Y3BQx5HMMaYrjpoAFDVn4vIhcCJgACPqmrEtoOOFrdmAa3dWUGf5Diy0xIO/s0dyE5PQBW+qqxjYEZiBGtnjDEdO2gAEJHhwFtN2zWLSJKI5KnqZrcrF0muZQDFFYwbmIazuWnXZKU6waO0otYCgDEmasLpb3gBaDly2hi61qPsHwOI3CBwMKisK65g3MCu9f83yU53HvolFTWRqJYxxoQlnAAQaLkddOjzePeq5I7mDCCC00C37dlHVV1jl2cANckKdR+VVNRGolrGGBOWcAJAqYg0b/sgIhfgHAvZo7gxC2hNcfcHgAH6pzrxtNQCgDEmisKZBfR94GkReQBnEPhL4Nuu1soFbpwH0LQH0JgB3QsACQE/fZLjrAvIGBNV4cwC2gAcGzq8XVS1wv1qRV6kZgE1BrU5m1izs4KhmcmkJIQTRzuXnZZgGYAxJqo6fHKJyHk4ZwFsCV26GbhIRLYAN6nqpmhUMFIiMQuopKKGk383n5HZKVyaP4SVRWXd7v9vkp2WaGMAxpio6mwM4Nc4J4EhIjOBq4FrgdeAP7tftciKxCyggs172FffSEVNA798dSWbv6rudv9/kyzLAIwxUdZZ34WqanXo8wuBv6rqImCRiNzgftUiKxIZwNJte4nzC7N/8jXW76xkzuqdXJI/JCL1y05LoKSiFlXt1poCY4wJV2cBQEL9/tXA6cBDLV7rcauVIjELaPm2MsYNTCch4Gfi4AwmDs6IVPXISkugriFI+b4GMpLjInZfY4zpSGddQH8ElgAFOGcAFACIyFRgh+s1i7BAaBC4q+sAgkFl+bYyJudG7qHfUtNagNJKmwlkjImODjMAVX08tAlcNrC0xUvFwHfdrlik+f3dywA2fVVFRW0DU3L7RLBW+2WnhVYDl9cyKjsy4wrGGNOZTucvqmoRUHTAtR737h+6PwawbNteACYPcTsDsIFgY0x0xHTvYRF5XERKRGSF22V1dxbQsm1lJMb5GJWVGslqNctOD20HUW4BwBgTHbHefP5vwNnRKKj7GUAZE3MyCLi0X39aQoCEgM9WAxtjoiasp5mInCgi3w19nhXaIrrbVPV9ICpHYXVnFlBDY5CV28uY7FL/P4CIkJ1uawGMMdETzqHw/w38F3Bb6FIc8A83K3VA+bNEpEBECkpLS7t8n+ZZQF0IAOt2VlJTH2SKS/3/TWw1sDEmmsLJAL4JnA9UAajqdiBq01RU9VFVzVfV/KysrC7fpzsZwPKivQCuZgDgHAxjGYAxJlrCCQB1qqqAAohIirtVckd3zgNYuq2M9MQAef2SI12tVrLTEywDMMZETTgB4HkReQToIyLfA+YAj7lbrcjz+QSRrs0CWrZtL5Nz+7i+RUNWagJl++qpqW90tRxjjIEwAoCq3gO8CPwLGAv8UlXvj0ThIvIM8DEwVkS2ich1kbhvRwI+OeQxgJr6RtbsqGCSSyuAW2qaCrrL1gIYY6IgrI3sVfVd4N1IF66qV0T6np3x++SQxwAWb91DQ1BdWwHcUvNq4Ipacvu6291kjDEHDQAiUkGo/7+FMpw9gn6qqhvdqJgb/HLoGcDzn39JWmKAk8d0fQA6XM2rgW0cwBgTBeFkAH8AtgP/xDkS8nJgILAWeBw4xa3KRdqhZgB7qup4a0Uxlx89hKR4v4s1c2Tb4fDGmCgKZxD4bFV9RFUrVLVcVR8FzlXV54C+LtcvogJ+Hw2HMAj8r8XbqGsIcuX0oS7War/MlHhELAMwxkRHOAEgKCKXiogv9HFpi9cid8J6FBxKBqCqPPPZVqYO7cO4geku18wR8Pvol5JAqW0HYYyJgnACwFXAt4ASYGfo86tFJAn4oYt1i7iAT8JeB/DZpt1sKK3iymOi8+6/SXZagm0IZ4yJioOOAYQGec/r4OWFka2Ouw4lA3jms62kJQaYOTnH5Vq1lpWWYFtCG2OiIpxZQInAdcAEWhwFqarXulgvV4S7DiDag78tZaclsLa4IqplGmO8KZwuoKdwZv2cBSwAcoEe+YTy+4RGPXgAmLN6J3UNQS6N0IHvh2JQnyRKKmrYV2ergY0x7gonAIxS1TuAKlV9EpgBTHK3Wu4I+Hw0hjEGsLBwF/1T45mQE53B35Ym5KQTVFhdXB71so0x3hJOAKgP/blXRCYCGUCeazVykT+MLiBV5cPCXZwwqr/re/+0Z+JgZ8uJlUVlUS/bGOMt4SwEe1RE+gK/AF4DUoE7XK2VSwJ+OehmcGt3VrCrso4TRvWPUq1ay8lIpG9yHCuKLAMwxrir0wAgIj6gXFX3AO8DI6JSK5eEkwEsXL8LgBNjFABEhImDM1ix3TIAY4y7Ou0CUtUgPWyuf2cCYUwDXVi4ixFZKeT0SYpSrdqaODiDdTsrqG2wgWBjjHvCGQN4V0R+JiJDRCSz6cP1mrngYBlAXUOQTzfujtm7/yYTczKob1TWFVfGtB7GmN4tnDGApvn+N7a4pvTA7qCAz8e+Tg5b+WLrHvbVN8as/7/JxMHO7KMV28uicg6BMcabwlkJPDwaFYmGg2UACwt34RM4bmS/KNaqraGZyaQlBlheVEZUD0wwxnjKQbuARCRZRH4hIo+Gvh4tIjPdr1rkOWMAHc8CWli4iylD+pCeGBfFWrUlIkzMybCpoMYYV4UzBvAEUAccH/p6G3CXazVykb+TzeDKa+pZ+uXemPf/N5k4OJ3VxRXUNx76GcbGGBOOcALASFX9HaEFYaq6D+dgmB7HWQfQfgD4qHAXQSXm/f9NJg7OoK4hSGGJDQQbY9wRTgCoC239rAAiMhLokdtV+n2+DgPAK19sp39qPEcNOzzOuGlaEbzcuoGMMS4JJwDcCbwNDBGRp4G5wC1uVsotHe0GuruqjrlrdvKNIwcT5w/nn8R9w/ulkBLvt3EAY4xrwpkFNFtEFgHH4nT93KSqu1yvmQs6Og/gtSVF1DcqFx2VG4Natc/nE8bnpLNiu20JYYxxRzjnAbwGPAO8pqpV7lfJPU4G0HZQ9V+Li5iQk84Rg6K/+2dnJg7O4KmPt3DpIx/TLyWesQPT+OGpowgcJlmKMaZnC+dJ8nvgJGCViLwgIheHDonpcdrLANYWV7C8qIyLph0+7/6bXHb0EL4+YQDgbFL3xznreb5gW4xrZYzpLcLpAloALBARP3Aa8D3gcaDbb5dF5GzgPsAP/EVVf9vde3amvTGAfy3eRsAnXHBkdI9+DMe4gek8dNVRgLNN9cV//pg/zlnHN6bmkBwfziJuY4zpWFh9CaFZQBcB3weOBp7sbsGhgPIgcA4wHrhCRMZ3976d8R9wIExDY5CXFhdx6rhs+qUmuFl0t4kIt54zjpKKWp74cHOsq2OM6QXCWQn8HLAa593/gzjrAn4UgbKPAQpVdaOq1gHPAhdE4L4dCvhbZwAfrN/FrspaLj6MBn87c3ReJmccMYA/z9/A7qq6WFfHGNPDhbsSeKSqfl9V3wOOE5EHI1D2YODLFl9vC11rRURmiUiBiBSUlpZ2q8ADxwDW7nSONj4+xnv/HIpbzh5LVV0DD84rjHVVjDE93EEDgKq+DUwSkf8nIptxtoFYE4Gy21tN3GaOpqo+qqr5qpqflZXVrQIPnAVUXdsAQEoP6k8fMyCNi4/K5amPt1BSURPr6hhjerAOA4CIjBGRX4rIauABnHfooqqnqur9ESh7GzCkxde5wPYI3LdDfp8QVAiGsoDqukaS4/34fD1rZ4tL84dQ1xhk+TZbJGaM6brOMoA1wOnAeap6YuihH8kjqj4HRovIcBGJBy7HOXPYNYHQg75RnQBQVdfYI2fTjM5OA+i1+wTtq2tEtfOT24wx3ddZALgIKAbmichjInI6EdwETlUbcI6bfAdnkPl5VV0Zqfu3x+9zmtvYnAE0kJLgd7NIV2Qkx5GVltBpANi2p5pjfj2Hd1YWR7Fm3VdYUsH0/53D795ZG+uqGNPrdRgAVPVlVb0MGAfMB34CDBCRh0Xk65EoXFXfUtUxqjpSVX8diXt2pikDaJoJVFXbMzMAgFFZqazvJADc9cZqSipqefrTrVGsVfdU1NQz66lFlNc08PjCTZSU2xiHMW4KZxC4SlWfVtWZOP30S4Bb3a6YG/xNXUCNLTKA+J6XAQCMHpDKhpLKdrtKPlhfytsri8nJSOTDQmeq6+EuGFR++vxStnxVzd0XT6YhqDw0f0Osq2VM1DUGlRVFZby6pIgvd1e7WtYhvf1V1d3AI6GPHifgb8oAnJlAVXWNZCTF9vSvrhqVnUpFbQM7y2sZmLF/Z466hiB3vraSvH7J3H/FNM57YCFvLd/Bt4/Li11lw/Dwgg3MXrWTO2aO55L8IXy+eTf//GwrPzhlJAPSe+TOI8aErWxfPf9evoO3VxazaPMeKkIzFAHGDEjltHEDuOKYIQzrlxLRcntm/0cXNWcATWMAtQ3kZPTMh8uo7FTAGQhuGQD+9tEmNpRW8cR3jmZSbgbjBqbx6pLth3UAKCyp4Pez13L+lByuPSEPgB+dNpqXFhfx8PwN3Hn+hNhW0GUrisr468JNFO3Zx1+/k09ajI8kNdFR1xBk/toSXv6iiLlrSqhrCDKsXzLnHZnD9OGZjMxK5ZONX/HemhL+8sFGTh2bZQGgOw4cA6juobOAYH8AWF9SwYmjnVPMdlfVcd+c9ZxxRDanjssG4Pwjc/jd22v5cnc1QzKTO71nVW0Dfp+QGBfdbrE/zllPUpyfO8+fgIjzfzQkM5mLj8rln59t5ZL8XFRhV2UtU3L70DclPqr168xXlbWkJcYRH2jbmxoMKhW1DZTvq6dvSjypCa1/1j7d+BW/f3cdn23aTUq8n331jfzf11dx9yVTolV9E2WqytJtZby0eBuvL93Onup6+qfGc9X0oXxz6mAmDc5o/h0AZ0fg/zhpBOU19SS78HvZM59+XXTgLKCqHjoLCCArNYGMpLhWM4HmrSmhqq6R/zx9dPO18yY7AeC1pdu58dRR7d6rriHIkx9t5r656zl1XDb3XzHV9fo3WVtcwZvLd3DDKSPJPODBfuOpo3hx0TZm/Glh87Whmcm8/sMTyUiO7btkVeUfn27lrjdWMSIrlYevmkZef+fd2aZdVdzy4lIWbdlD08LztIQA1588gmtPHE5Q4bf/Xs0/PtlKTkYiv5hxBJcePYRHFmzgwXkbOHP8AL4+YSAAlbUNLP1yL/l5fUkIdP1ndV9dIzc8vYhpQ/vyoxY/HyY69lTV8VzBl7y4aBuFJZUkBHycOX4AF03L5aTR/Q+6xXu6S1mhpwJAmwygB88CEhFGZbeeCbRgXSn9UxOYmJPRfG1IZjJHDevL6x0EgE82fsXtLy9nQ2kVqQkBPt34VVTq3+S+uetIiQ/wvZNGtHltSGYyj12Tz/a9++ifmkBNfSM/fX4pP31hCY9+Kz9mC/j2VNXxX/9axuxVOzl2RCZriis474GF/P6SKZRW1nLXG6uJD/i4/uSR9EuJJy0xwJzVJdwzex1/+2gL8X5hR3kN1504nJ99fSxJoYkIN50+hvfWlHLbS8uZNqwvX2zdyy9fXcGOshoGpCfwvZNGcOX0oYf8M6uq3PbSMuatLWXe2lKGZ6Uwc/Lht/ttb7B5VxV1jUHGDEhrvvbB+lJufn4ppRW15A/ry28unMSMyYNce6gfip759Oui/WMAQeoagtQ1BnvsLCCA0dmpvLtqJ+BkNR+sL+XUcdltHowXHJnDL19dyZricsYN3L+L99avqvnOE58xID2Rx7+Tz8bSKu56czWlFbVkpbm/O+qq7eW8tbyY/zxtFH2S2+/WOXVsdquv91TVcefrq3h4wQZuPHUUVbUNvLl8B8VlNYzISmFUdioj+qe22yUTCTvLa7jwoY8oqajhFzOO4NoThlO0dx83PL2YWU8tAuCk0f25++IprcZmLjt6KIu27OH3s9dSVdvA/VdOa3P+dHzAx72XTeH8+z/k3Ps+oKSilrED0vjJmWN4afE27npzNQ/N38B3js/j28cNa/43a2gMUrR3H0P6JrcbFP+6cBOvLNnOTaeP5sPCXdzy4jJGZ6cxdmBam+81XVNYUsmf5q7n9WXbUYVpQ/tw9bHDWLuzgkcWbGRUdipPfOfo5rO+DxeeCgAtM4B9dc6i5uSEnvtPMCo7lWc//5LdVXVs3V3Nnup6Th7Tdr+kcycN4n/eWMXdb6/l0W/n4/cJqsrtrywn4PPx7KxjGZSRRFKc8+5/1Y5yTk7r3r5L7Snau4//9+81pCUGOGJQOu+sLCYtMcB1J7Z999+Ra47PY/HWvfx+9lpWbS9n3toSqutaL1AfmpnMiz84juy0yA7w19Q3MuvvBeypruP5649j6lDnAT4kM5kXvn8cf5q7nkF9krjqmKHtPoiPGtaXf37v2E7LGDcwnVvPGcfd76zl52eNZdbXRhDn93Fp/hAKNu/mwXmF/OHddfx5wQbOn5LDjrIaCjbvpqqukRmTBvHHy49sda71h4W7+N+3VnPOxIH8+IzRXDV9KDPuX8j1TxXw6g9PbDML7vPNu6msbeCUMVmt+qLbEwwqhaWVVNTUM21o34N+f2+zs7yGBWtLmbtmJ++u2klinJ8fnOx0Zf7z063c/PxSAK6cPpQ7ZoxvzvQOJz336dcFTRlAQ6NSVde0Edzh958SrpYzgT7e8BUicNLotg/u/qkJ3DFzPL98dSV3v7OWW88ZxytLivhg/S7+7wUTGJSRBMD4HCc7WLm9rN1A0pnqugaWbN3LsSP6tfvwK6+p59onPmfr7moCfmleoPaTM8YcUn++iPDbiyaxbmcF89eWcN7kHC49OpfxgzLYtKuKldvL+OWrK/nekwU8O+u4iP3SqSo/f3EZy4rKeOTqo5of/k0S4/zccva4iJR17YnDueb4vOaf1yb5eZk88d1jWFNcziMLNvKvxdvI65fChdNySYzz8dgHm6htCPLgVVPxifDkR5u59911jMpO5Z5LpiAiZKcn8vBV07j80U84/4GFfPu4PC6elktpZS2/eWs1c9eUAM472F/MHM+0A9pZVl3Pa0uLmL1qJ0u27m2ernj910Zw6znjPBEEivbu42fPL+XjUHfpgPQE/uOkEcz62gj6h84Vue7E4Xy88SsCPh/HDM+MZXU75akA0LQOoDGoVIcCQE/PAMCZCbRgXQmTc/u0GUht8q1jh7G2uII/L9hAVloCD84rdNLU6cOavycjKY4hmUmsPMSD6INB5Yf//IL31pQwbmAaPz9rLKeNy25+GNQ1BPnBPxaxcVclT373GI4b2Y/tZTVs2VXF0V345UiOD/DKjScAtJqxND4nnfE56fRJjmfWUwXc/PwSHrxyWrfHCoJB5b6563l96XZuOXts8wCtmw58+Lc0bmA69152JL+/ZEqrtg3NTOaOV1dyzeOfsauyjsKSSk4dm8WvvzmJlBY/5/l5mTx2TT73z13vZIbvrKG+UUmO83PrOePomxzHPbPXceFDHzF9eCY5fZLITImnpKKWd1YWU9cQZFR2KucfmcPUoX1ZvHUPj7y/kbrGIL+cOT6mQaCqtoGH5hcyd3UJKQkBMpLi6JcSz7hB6Ywf5Px8tLf2pzGonf6bN1mwrpQfP/sF9Y3a/HM+bmBamzaLCMeP7B+xdrml5z79uqBpFlBDUKmqdboNenIGkJORRHK8n0Vb9rDky7388LSOZ3eICHeeP4ENpZX8zxuriPMLv7lwcpuH44RBGaw6xADwwLxC3ltTwpXTh/JR4S6ue7KAKbkZ5OdlMjo7lY83fsWHhV/x+0umcPwo55dicJ8kBvdJOvRGh3Q2VfXM8QO4/dwjuOvN1fz27TXc1oV3pqrKki/38vrSHby5fDs7y2v55tTB/ODkkV2uc6Qd+H/3rePyiA/4uPWl5eT2TeIv387n9COy2237qWOzOXVsNiuKynj2860kxfn5/skjm0/Gmzk5h0fe38j8tSV8tmk3e6rriA/4uOLoIVySP4QJOenN971o2mASA34e/3AT1bWNzJwyiD5J8fRPi2/OLtvTGFQWFu5iYHpi2OMRS77cS3VdQ5uHq6ry2tLt/OatNRSX1zSf8VFSUcPyojJeWLT/LO3cvkkcMSidYZnJbP6qmtU7yimpqOHHZ4zhhlNGtvn3UlXWl1Ty4qJtPPbBRsYOSOOhq6YxIis1rDofzjwVAAItFoLVNjgB4HDslwuXzyeMzErljaU7CCoH7baJ8/t4+Kqj+O7fPmfGpEHt/tJNyEnn7ZXFVNY2tJm33p75a0u4d846vjl1ML/+xkQagsoLBdt45rOtPP3pFmrqnVXXPzljDBdF8eS1604cztbd1Tz6/kYqahr4nwsmHHSqHThTOF/+oohXlxSx5atq4v0+Th6bxXlTcjh34sDDvovjsqOHMn14PwZmJIa1nmPi4AzuGjypzfWUhAA3nzmGm88c03xNVdttv4hwx8wjiA/4+POCDTxXsP+cp5NG9+fHZ4xpNeDdGFTeWLadP81dz4bSKgDGDkjjvCmDmDk5p3k6bUu7q+r47b9X83yB8yA/44gB/HLmeAb3TeLfK3bw8PwNrNxezqTBGTx41VSOGtY6syytqGXl9jJWbi9n9Q7nY/7aEob1S+GoYX2pqm3g7nfWsquyljtmjMfnEzbvquLpT7fwzsqdbA1tyXDxUbn8zwUTe/RzoyVPBYDmMYBgsHkQuCcdBtOeUdmpLC8qIyMpjim5B59h0Dclvrn7pD1N4wCrd5RzdF7n3TNf7q7mx88tYeyANP73m5MQEeL8wpXTh3Ll9KEEg0rR3n1U1DRwxKDozjgREe48bwLpiXE8MK+Qor37ePDKqR2uslVVHpxXyD2z1yHinBJ346mjOHviwMNiut6haO8BGgmdBb+mM6svP3oIpZW17K2uZ93OCh5fuImLHv6I40f2o29KPLsrnQkLRXv3MXZAGn+6Yipl1XW8tnQ798xexz2z1zEhJ51zJw0it28Su6vqKKmo5ZnPtlJZ08D1J48gIymOB94r5Ix7F5CdlsC2PfsY0T+Fuy+ezIXTctvtyslKS+CUsdmccsCssibBoHLXm6t5/MNN7NhbQ31jkPfWluAX4cTR/Zn1tRGcfkR2pxlNT9Szn36HqGUGUNUUAHroQrAmTeMAJ4axmCQcE0JrCFYWlR00ADw0fwO19UEe+dZR7b4j8vnkoKuP3eTzCT87ayy5fZO4/ZUVXPTwR/zmwklt3h3WNjRy20vLeWlxERccmcNt5xzRagqnCV9e/5TmAHTm+AF894Q8nvp4C//8bCvFZTX0S41ncm4Gt507jnMnDmruxvrWcXls37uPt5bv4M3lO7i7xXbgIjB9eCa/On9ic9Z64dRcfvfOGnbsdabjnjl+YFh9+B3x+Zwspn9aPL97ey39U+P50WmjuXr6ULJ78V5UngoA/hbTQJuOg+ypC8GajA4FgEOdtdORAekJ9EuJP+hAcF1DkH+v2MFZEwZEfH+SSLv8mKEM7pvEz19YxkUPf8w3pw7mptNHU1HTQGFpBf/8dCufb97DzWeO4UenjTrsu3l6kuT4ANefPJLrwxg7yemTxH+cNIL/OGkExWU1VNbWk5nirHg/8OE+MCORP1x6ZETrKiLccMoovj5+IEMyk7q18rqn6NlPv0MUaNoKorFFBtDDA8DXxmTx87PGcl6EVnaKCONz0g8aAD4s3MXe6nrOm9IzVpSeNDqLuT89mYfmF/LY+5t4+Yui5teS4/386YqpnN9D2uIFTgYWm3feTVm1F/Tsp98hai8D6OmDOYlx/g73+OmqCTkZ/HXhRuoagh2uqH196XbSEwPtrjs4XKUkBPj5WeO4NH8Ic1aXMLhPIqOyUxmameLaymFjDmeeCgAt1wFU1TUS7/fZL347JuSkU9+orNtZ0e7S9Zr6Rmav2smMSYN65L/fsH4pXHfi8FhXw5iY63m/vd3QchZQdV0DyT18ANgtE0IzgTpaDzBvTQmVtQ09pvvHGNM+TwWAVrOAaht7fP+/W/L6pZAS72fl9rJ2X3992Xb6p8Zz7IjDd4m7MebgPBUAWo0B1DWQ3MP7/93i8zkDwZ9u2t3mzOHK2gbmri5hxqRBEZl2aoyJHU/9BvsPWAfQk/cBcttF03JZU1zB++t3tbr+7qpiahuC1v1jTC/gyQDQNAuoJ+8D5LYLp+WSk5HI/XPXN2cBNfWN3D+3kGH9ktvsEmmM6Xk8FQD2rwMIOhmAjQF0KD7g4/unjKRgyx4+2bgbcM7u3biriru+MTFmp3EZYyInJgFARC4RkZUiEhSR/GiVe+AYQE/fBsJtl+YPISstgQfmrWf5tjIe+2Ajl+bn9qi5/8aYjsUqA1gBXAi8H81CD5wFZBlA5xLj/Mw6aQQfFn7FrKcK6JcSz+0zxse6WsaYCIlJAFDV1aq69uDfGVltMgAbAzioK6cPpW9yHDvKarjrGxPbPUzDGNMzHfZvgUVkFjALYOjQod26V/OZwI1Ktc0CCktKQoDfXTyFDaWVUTkJyxgTPa49AUVkDtDeE+N2VX013Puo6qPAowD5+fl6kG/vVFMGUFlbD/Ts08Ci6czxAziTAbGuhjEmwlwLAKp6hlv37ioRwe8TKmp6/nnAxhjTXZ6aBgpOFlBeYxmAMcbEahroN0VkG3Ac8KaIvBOtsgM+oXxf02EwFgCMMd4Vkz4QVX0ZeDkWZbfMAGwaqDHGyzzXBeRkAKEuIFsIZozxMM8FAL/PR3lN7zgP2BhjusNzAaBVBmABwBjjYZ4LAH6f0BB0lhPYiWDGGC/zXABoOhcYLAMwxnib5wJA02pgEUiM81zzjTGmmeeegE37AaXEBxCxPe2NMd7luQDgDx0KY4vAjDFe57kA0JwB2D5AxhiP81wAaBoDsAzAGON1ngsALccAjDHGyzwXAJozAFsDYIzxOM8FgKZ1AJYBGGO8znMBwGYBGWOMw3MBwGYBGWOMw3MBwGYBGWOMw3MBwDIAY4xxeC4AWAZgjDEOzwWAgAUAY4wBPBgA9s8Csi4gY4y3eS4A7B8DsAzAGONtngsAfn9TF5BlAMYYb/NcALC9gIwxxuG5AGB7ARljjCMmAUBE7haRNSKyTEReFpE+0SrbMgBjjHHEKgN4F5ioqpOBdcBt0Sq4eRaQZQDGGI+LSQBQ1dmq2hD68hMgN1plN68DiLMAYIzxtsOhH+Ra4LmOXhSRWcAsgKFDh3a7sPOm5NAnOY6A33PDH8YY04qoqjs3FpkDDGznpdtV9dXQ99wO5AMXahgVyc/P14KCgshW1BhjejkRWaSq+Qdedy0DUNUzDlKha4CZwOnhPPyNMcZEVky6gETkbOC/gJNVtToWdTDGGK+LVUf4A0Aa8K6ILBGRP8eoHsYY41kxyQBUdVQsyjXGGLOfTYUxxhiPsgBgjDEeZQHAGGM8ygKAMcZ4lGsLwdwgIqXAli7+9f7ArghWp6fwYru92GbwZru92GY49HYPU9WsAy/2qADQHSJS0N5KuN7Oi+32YpvBm+32Ypshcu22LiBjjPEoCwDGGONRXgoAj8a6AjHixXZ7sc3gzXZ7sc0QoXZ7ZgzAGGNMa17KAIwxxrRgAcAYYzzKEwFARM4WkbUiUigit8a6Pm4QkSEiMk9EVovIShG5KXQ9U0TeFZH1oT/7xrqukSYifhH5QkTeCH3thTb3EZEXRWRN6P/8uN7ebhH5Sehne4WIPCMiib2xzSLyuIiUiMiKFtc6bKeI3BZ6tq0VkbMOpaxeHwBExA88CJwDjAeuEJHxsa2VKxqAn6rqEcCxwI2hdt4KzFXV0cDc0Ne9zU3A6hZfe6HN9wFvq+o4YApO+3ttu0VkMPCfQL6qTgT8wOX0zjb/DTj7gGvttjP0O345MCH0dx4KPfPC0usDAHAMUKiqG1W1DngWuCDGdYo4Vd2hqotDn1fgPBAG47T1ydC3PQl8IyYVdImI5AIzgL+0uNzb25wOfA34K4Cq1qnqXnp5u3G2r08SkQCQDGynF7ZZVd8Hdh9wuaN2XgA8q6q1qroJKMR55oXFCwFgMPBli6+3ha71WiKSB0wFPgUGqOoOcIIEkB3Dqrnhj8AtQLDFtd7e5hFAKfBEqOvrLyKSQi9ut6oWAfcAW4EdQJmqzqYXt/kAHbWzW883LwQAaedar537KiKpwL+AH6tqeazr4yYRmQmUqOqiWNclygLANOBhVZ0KVNE7uj46FOrzvgAYDuQAKSJydWxrdVjo1vPNCwFgGzCkxde5OKljryMicTgP/6dV9aXQ5Z0iMij0+iCgJFb1c8EJwPkishmna+80EfkHvbvN4PxMb1PVT0Nfv4gTEHpzu88ANqlqqarWAy8Bx9O729xSR+3s1vPNCwHgc2C0iAwXkXicAZPXYlyniBMRwekTXq2qf2jx0mvANaHPrwFejXbd3KKqt6lqrqrm4fy/vqeqV9OL2wygqsXAlyIyNnTpdGAVvbvdW4FjRSQ59LN+Os44V29uc0sdtfM14HIRSRCR4cBo4LOw76qqvf4DOBdYB2wAbo91fVxq44k4qd8yYEno41ygH86sgfWhPzNjXVeX2n8K8Ebo817fZuBIoCD0//0K0Le3txv4FbAGWAE8BST0xjYDz+CMc9TjvMO/rrN2AreHnm1rgXMOpSzbCsIYYzzKC11Axhhj2mEBwBhjPMoCgDHGeJQFAGOM8SgLAMYY41EWAIwniEijiCxp8dHpylkR+b6IfDsC5W4Wkf5d+HtnicidItJXRN7qbj2MaU8g1hUwJkr2qeqR4X6zqv7ZxbqE4yRgHs6mbx/GuC6ml7IAYDwttI3Ec8CpoUtXqmqhiNwJVKrqPSLyn8D3cbbcXqWql4tIJvA4zsZs1cAsVV0mIv1wFvJk4azIlBZlXY2zpXE8zkZ9N6hq4wH1uQy4LXTfC4ABQLmITFfV8934NzDeZV1AxiuSDugCuqzFa+WqegzwAM7uoge6FZiqqpNxAgE4q1K/CF37P8DfQ9f/G1ioziZtrwFDAUTkCOAy4IRQJtIIXHVgQar6HM6+PitUdRLOqtep9vA3brAMwHhFZ11Az7T48952Xl8GPC0ir+BsuwDO1hsXAajqeyLST0QycLpsLgxdf1NE9oS+/3TgKOBzZysbkuh447LROEv7AZLVOd/BmIizAGBM6+1z29sbZQbOg/184A4RmUDn2/C2dw8BnlTV2zqriIgUAP2BgIisAgaJyBLgR6r6QaetMOYQWReQMU7XTNOfH7d8QUR8wBBVnYdz8EwfIBV4n1AXjoicAuxS5/yFltfPwdmkDZwNvC4WkezQa5kiMuzAiqhqPvAmTv//73A2LzzSHv7GDZYBGK9ICr2TbvK2qjZNBU0QkU9x3hBdccDf8wP/CHXvCHCvqu4NDRI/ISLLcAaBm7bq/RXwjIgsBhbgbGOMqq4SkV8As0NBpR64EdjSTl2n4QwW3wD8oZ3XjYkI2w3UeFpoFlC+qu6KdV2MiTbrAjLGGI+yDMAYYzzKMgBjjPEoCwDGGONRFgCMMcajLAAYY4xHWQAwxhiP+v9ZscHAyL3bAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(average_scores)), average_scores)\n",
    "plt.ylabel('Average Scores')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Watch a trained agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def watch_banana_agent(agent, env, n_episodes=4, n_steps=300):\n",
    "\n",
    "                                   \n",
    "    \n",
    "#     for episode in range(n_episodes):\n",
    "        \n",
    "#         env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "#         state = env_info.vector_observations[0]            # get the current state\n",
    "#         score = 0                                          # initialize the score\n",
    "        \n",
    "#         for step in range(n_steps):\n",
    "\n",
    "#             action = agent.act(state)                 # select an action\n",
    "#             env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "#             next_state = env_info.vector_observations[0]   # get the next state\n",
    "#             reward = env_info.rewards[0]                   # get the reward\n",
    "#             done = env_info.local_done[0]                  # see if episode has finished\n",
    "#             score += reward                                # update the score\n",
    "#             state = next_state                             # roll over the state to next time step\n",
    "#             if done:                                       # exit loop if episode finished\n",
    "#                 break\n",
    "\n",
    "#         print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watch_banana_agent(agent, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
