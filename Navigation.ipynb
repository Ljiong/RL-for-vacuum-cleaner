{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.environment import UnityEnvironment as UE\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from collections import deque\n",
    "from dqn_agent import Agent\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_PATH = \"environment-MACOS/environment-MACOS.app\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialise customised Banana Collecter environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_env(ENV_PATH):\n",
    "    # env = UnityEnvironment(file_name=ENV_PATH)\n",
    "    env = UE(base_port=5004,file_name=ENV_PATH, seed=1, side_channels=[])\n",
    "    env.step()\n",
    "    # in this project, we are only using one agent, so we will only work on the first `brain` in the environmet\n",
    "    # get the default brain\n",
    "    # brain_name = env.brain_names[0]\n",
    "    brain_name = list(env.behavior_specs.keys())[0]\n",
    "    # brain = env.brains[brain_name]\n",
    "    brain = env.behavior_specs[brain_name]\n",
    "    return env, brain, brain_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = UE(file_name=ENV_PATH, seed=1, side_channels=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = env.behavior_specs.keys()\n",
    "# print(list(test)[0])\n",
    "# for t in test:\n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain_name = list(env.behavior_specs.keys())[0]\n",
    "# print(brain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain = env.behavior_specs[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0613 20:58:27.195118000 8597757440 fork_posix.cc:76]                  Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n"
     ]
    }
   ],
   "source": [
    "env, brain, brain_name = initialise_env(ENV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(brain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先让他走几步直到需要交互\n",
    "# env.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialise the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BehaviorSpec(observation_specs=[ObservationSpec(shape=(84, 84, 3), dimension_property=(<DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.NONE: 1>), observation_type=<ObservationType.DEFAULT: 0>, name='CameraSensor'), ObservationSpec(shape=(0,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor'), ObservationSpec(shape=(4,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor_size4')], action_spec=ActionSpec(continuous_size=0, discrete_branches=(5,)))\n"
     ]
    }
   ],
   "source": [
    "spec = env.behavior_specs['My Behavior?team=0']\n",
    "print(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment\n",
    "#env_info = env.reset(train_mode=True)[brain_name]\n",
    "env_info = env.reset()\n",
    "#action_size = brain.vector_action_space_size\n",
    "#state_size = len(env_info.vector_observations[0])\n",
    "#agent = Agent(state_size=state_size, action_size=action_size, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(env_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = list(brain.action_spec)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_steps, terminal_steps = env.get_steps(brain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change\n",
    "# decision_steps.obs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 84, 84, 3)\n",
      "torch.Size([84, 84, 3])\n"
     ]
    }
   ],
   "source": [
    "state = decision_steps.obs[0]\n",
    "print(state.shape)\n",
    "state = torch.from_numpy(state).float().squeeze(0).to('cpu')\n",
    "print(state.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "listb = [[[1,2,3],[4,5,6],[7,8,9]],[12,3,4]]\n",
    "print(np.shape(listb[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(decision_steps.obs[0]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(a[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21168\n"
     ]
    }
   ],
   "source": [
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = len(brain.observation_specs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ObservationSpec(shape=(84, 84, 3), dimension_property=(<DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.TRANSLATIONAL_EQUIVARIANCE: 2>, <DimensionProperty.NONE: 1>), observation_type=<ObservationType.DEFAULT: 0>, name='CameraSensor'), ObservationSpec(shape=(0,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor'), ObservationSpec(shape=(4,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor_size4')]\n"
     ]
    }
   ],
   "source": [
    "print(brain.observation_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_size = (84, 84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(action_size)\n",
    "# # import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# nn.Conv2d(3, 32, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_size = len(env_info.vector_observations[0])\n",
    "# state size 要改\n",
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# !pip3 show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms as transforms\n",
    "actions = []\n",
    "for act in range(5):\n",
    "    actions.append(spec.action_spec.empty_action(1))\n",
    "    actions[act].add_discrete(np.int32([[act]]))\n",
    "stop = actions[0]\n",
    "forward = actions[1]\n",
    "backward = actions[2]\n",
    "turn_right = actions[3]\n",
    "turn_left = actions[4]\n",
    "def train_dqn(agent, n_episodes=2, max_t=10, eps_start=1.0, eps_end=0.1, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        decision_steps, terminal_steps = env.get_steps(brain_name)\n",
    "        state = np.moveaxis(decision_steps.obs[0], -1, 0)\n",
    "        tracked_agent = -1\n",
    "        done = False\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            if tracked_agent == -1 and len(decision_steps) >= 1:\n",
    "                tracked_agent = decision_steps.agent_id[0]\n",
    "            if not state.shape == (3, 1, 84, 84):\n",
    "                continue\n",
    "                \n",
    "            action = agent.act(state, eps)\n",
    "            env.set_actions(brain_name, actions[action])\n",
    "            env.step()\n",
    "            decision_steps, terminal_steps = env.get_steps(brain_name)\n",
    "            \n",
    "            next_state = np.moveaxis(decision_steps.obs[0], -1, 0)   # get the next state\n",
    "            \n",
    "            if tracked_agent in decision_steps:# The agent requested a decision\n",
    "                reward = decision_steps[tracked_agent].reward  # get the reward\n",
    "                agent.step(state, action, reward, next_state, False)\n",
    "            if tracked_agent in terminal_steps: # The agent terminated its episode\n",
    "                rewards += terminal_steps[tracked_agent].reward# get the reward\n",
    "                agent.step(state, action, reward, next_state, True)\n",
    "                break\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "        print(score)\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            print('saved temporary learned weight')\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            print('agent done training')\n",
    "            break\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Episode 1\tAverage Score: 0.000.0\n",
      "Episode 2\tAverage Score: 0.000.0\n",
      "Episode 3\tAverage Score: 0.00-1.0\n",
      "Episode 4\tAverage Score: -0.25-1.0\n",
      "Episode 5\tAverage Score: -0.40-1.0\n",
      "Episode 6\tAverage Score: -0.50torch.Size([64, 3, 84, 84]) torch.Size([64]) torch.Size([64]) torch.Size([64, 3, 84, 84]) torch.Size([64])\n",
      "0.0\n",
      "Episode 7\tAverage Score: -0.43torch.Size([64, 3, 84, 84]) torch.Size([64]) torch.Size([64]) torch.Size([64, 3, 84, 84]) torch.Size([64])\n",
      "torch.Size([64, 3, 84, 84]) torch.Size([64]) torch.Size([64]) torch.Size([64, 3, 84, 84]) torch.Size([64])\n",
      "torch.Size([64, 3, 84, 84]) torch.Size([64]) torch.Size([64]) torch.Size([64, 3, 84, 84]) torch.Size([64])\n",
      "0.0\n",
      "Episode 8\tAverage Score: -0.38torch.Size([64, 3, 84, 84]) torch.Size([64]) torch.Size([64]) torch.Size([64, 3, 84, 84]) torch.Size([64])\n",
      "torch.Size([64, 3, 84, 84]) torch.Size([64]) torch.Size([64]) torch.Size([64, 3, 84, 84]) torch.Size([64])\n",
      "-1.0\n",
      "Episode 9\tAverage Score: -0.44torch.Size([64, 3, 84, 84]) torch.Size([64]) torch.Size([64]) torch.Size([64, 3, 84, 84]) torch.Size([64])\n",
      "torch.Size([64, 3, 84, 84]) torch.Size([64]) torch.Size([64]) torch.Size([64, 3, 84, 84]) torch.Size([64])\n",
      "torch.Size([64, 3, 84, 84]) torch.Size([64]) torch.Size([64]) torch.Size([64, 3, 84, 84]) torch.Size([64])\n",
      "-1.0\n",
      "Episode 10\tAverage Score: -0.50"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('./checkpoint.pth'):\n",
    "    # load the weights from file\n",
    "    agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "    \n",
    "scores = train_dqn(agent, n_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./checkpoint.pth'):\n",
    "    # load the weights from file\n",
    "    agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Watch a trained agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watch_banana_agent(agent, env, n_episodes=4, n_steps=300):\n",
    "\n",
    "                                   \n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        \n",
    "        env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]            # get the current state\n",
    "        score = 0                                          # initialize the score\n",
    "        \n",
    "        for step in range(n_steps):\n",
    "\n",
    "            action = agent.act(state)                 # select an action\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            score += reward                                # update the score\n",
    "            state = next_state                             # roll over the state to next time step\n",
    "            if done:                                       # exit loop if episode finished\n",
    "                break\n",
    "\n",
    "        print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reset() got an unexpected keyword argument 'train_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p2/fj_ptp_x055gqt839fj3ws6m0000gn/T/ipykernel_67920/1660049170.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwatch_banana_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/p2/fj_ptp_x055gqt839fj3ws6m0000gn/T/ipykernel_67920/2633861598.py\u001b[0m in \u001b[0;36mwatch_banana_agent\u001b[0;34m(agent, env, n_episodes, n_steps)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# reset the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m            \u001b[0;31m# get the current state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m                                          \u001b[0;31m# initialize the score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reset() got an unexpected keyword argument 'train_mode'"
     ]
    }
   ],
   "source": [
    "watch_banana_agent(agent, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
